{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Likelihood: Summed Likelihood\n",
    "\n",
    "\n",
    "## Summed Likelihood Analysis\n",
    "The summed likelihood method available in the Fermi Science tools is a way of performing a joint likelihood fit on two data selections using the same XML model, i.e., you can estimate a single parameter simultaneously for multiple data sets. Remember this is exactly what the likelihood formalism implies. You can't stop me from writing down a likelihood function containing as many independent data sets as I like as long as I have a response matrix for each selection. \n",
    "\n",
    "This is useful if you want to do the following:\n",
    "\n",
    "* Coanalysis of Front and Back selections (not using the combined IRF for whatever reason)\n",
    "* Coanalysis of separate time intervals\n",
    "* Coanalysis of separate energy ranges\n",
    "* Pass 8 PSF type analysis\n",
    "* Pass 8 EDISP type analysis\n",
    "\n",
    "There are many other possible applications. Remember that the likelihood framework is very flexible! You're mainly limited by your imagination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with 3C 279\n",
    "We're going to use the 3C 279 data set that we know and love and perform a seperate front/back analysis and then perform a summed likelihood at the end.  We're going to do a binned anlysis this time since we haven't really done one yet.\n",
    "\n",
    "I've provided a lot of the ancillary files in a tarball linked to the agenda.  Let's look at the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anatest\r\n",
      "FermiLineTutorial\r\n",
      "junk\r\n",
      "LineTutorial.tar.gz\r\n",
      "Summed_and_Composite_orig.ipynb\r\n",
      "Summed Likelihood.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you need to place the galactic diffuse model and the raw data files in the working directory (gll_iem_v05_rev1.fit, L1405221252264C652E7F67_PH00.fits and L1405221252264C652E7F67_SC00.fits).  I didn't put them in the tar ball since they are big and you already have them in your VM.  You'll need to copy or link isotropic models for the front and back data selections into your working directory (iso_source_back_v05_rev1.fits and iso_source_front_v05_rev1.fits) -- check.  These two files are in $FERMI_DIR/refdata/fermi/galdiffuse. \n",
    "\n",
    "Now, we need to import some functions so that we can work on these data.  Note that you don't have to run all of these.  If I say 'Don't run this', don't run it; the output file is already generated for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gt_apps import filter, maketime, expMap, expCube, evtbin, srcMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Front and Back Events\n",
    "\n",
    "**<font color='red'>Don't run these commands</font>** (unless you want to rerun everything).\n",
    "\n",
    "We need to run gtselect (called 'filter' in python) twice.  Once, we select only the front events and the other time we select only back events.  You do this with the hidden parameter 'convtype'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter['rad'] = 15\n",
    "filter['evclass'] = 2\n",
    "filter['infile'] = \"L1405221252264C652E7F67_PH00.fits\"\n",
    "filter['outfile'] = \"3C279_front_filtered.fits\"\n",
    "filter['ra'] = 194.046527\n",
    "filter['dec'] = -5.789312\n",
    "filter['tmin'] = 239557417\n",
    "filter['tmax'] = 255398400\n",
    "filter['emin'] = 100\n",
    "filter['emax'] = 100000\n",
    "filter['zmax'] = 100\n",
    "filter['convtype'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtselect infile=L1405221252264C652E7F67_PH00.fits outfile=3C279_front_filtered.fits ra=194.046527 dec=-5.789312 rad=15.0 tmin=239557417.0 tmax=255398400.0 emin=100.0 emax=100000.0 zmax=100.0 evclsmin=\"INDEF\" evclsmax=\"INDEF\" evclass=2 convtype=0 phasemin=0.0 phasemax=1.0 evtable=\"EVENTS\" chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "Done.\n",
      "real 1.28\n",
      "user 0.37\n",
      "sys 0.56\n"
     ]
    }
   ],
   "source": [
    "filter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filter['rad'] = 15\n",
    "filter['evclass'] = 2\n",
    "filter['infile'] = \"L1405221252264C652E7F67_PH00.fits\"\n",
    "filter['outfile'] = \"3C279_back_filtered.fits\"\n",
    "filter['ra'] = 194.046527\n",
    "filter['dec'] = -5.789312\n",
    "filter['tmin'] = 239557417\n",
    "filter['tmax'] = 255398400\n",
    "filter['emin'] = 100\n",
    "filter['emax'] = 100000\n",
    "filter['zmax'] = 100\n",
    "filter['convtype'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtselect infile=L1405221252264C652E7F67_PH00.fits outfile=3C279_back_filtered.fits ra=194.046527 dec=-5.789312 rad=15.0 tmin=239557417.0 tmax=255398400.0 emin=100.0 emax=100000.0 zmax=100.0 evclsmin=\"INDEF\" evclsmax=\"INDEF\" evclass=2 convtype=1 phasemin=0.0 phasemax=1.0 evtable=\"EVENTS\" chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "Done.\n",
      "real 1.28\n",
      "user 0.42\n",
      "sys 0.52\n"
     ]
    }
   ],
   "source": [
    "filter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the GTIs\n",
    "\n",
    "**<font color='red'>Don't run these commands.</font>** (unless you want to rerun everything).\n",
    "\n",
    "Now, we need to find the GTIs for each data set (front and back)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maketime['scfile'] = 'L1405221252264C652E7F67_SC00.fits'\n",
    "maketime['filter'] = '(DATA_QUAL==1)&&(LAT_CONFIG==1)'\n",
    "maketime['roicut'] = 'yes'\n",
    "maketime['evfile'] = '3C279_front_filtered.fits'\n",
    "maketime['outfile'] = '3C279_front_filtered_gti.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtmktime scfile=L1405221252264C652E7F67_SC00.fits sctable=\"SC_DATA\" filter=\"(DATA_QUAL==1)&&(LAT_CONFIG==1)\" roicut=yes evfile=3C279_front_filtered.fits evtable=\"EVENTS\" outfile=\"3C279_front_filtered_gti.fits\" apply_filter=yes overwrite=no header_obstimes=yes tstart=0.0 tstop=0.0 gtifile=\"default\" chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "real 2.85\n",
      "user 0.82\n",
      "sys 1.30\n"
     ]
    }
   ],
   "source": [
    "maketime.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maketime['scfile'] = 'L1405221252264C652E7F67_SC00.fits'\n",
    "maketime['filter'] = '(DATA_QUAL==1)&&(LAT_CONFIG==1)'\n",
    "maketime['roicut'] = 'yes'\n",
    "maketime['evfile'] = '3C279_back_filtered.fits'\n",
    "maketime['outfile'] = '3C279_back_filtered_gti.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtmktime scfile=L1405221252264C652E7F67_SC00.fits sctable=\"SC_DATA\" filter=\"(DATA_QUAL==1)&&(LAT_CONFIG==1)\" roicut=yes evfile=3C279_back_filtered.fits evtable=\"EVENTS\" outfile=\"3C279_back_filtered_gti.fits\" apply_filter=yes overwrite=no header_obstimes=yes tstart=0.0 tstop=0.0 gtifile=\"default\" chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "real 2.76\n",
      "user 0.83\n",
      "sys 1.21\n"
     ]
    }
   ],
   "source": [
    "maketime.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the Livetime Cube\n",
    "\n",
    "You only need to do this once since we made the exact same time cuts and used the same GTI filter on both data sets.\n",
    "\n",
    "**<font color='red'>Don't run these commands.</font>** (unless you want to rerun everything).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expCube['evfile'] = '3C279_front_filtered_gti.fits'\n",
    "expCube['scfile'] = 'L1405221252264C652E7F67_SC00.fits'\n",
    "expCube['outfile'] = '3C279_front_ltcube.fits'\n",
    "expCube['dcostheta'] = 0.025\n",
    "expCube['binsz'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtltcube evfile=\"3C279_front_filtered_gti.fits\" evtable=\"EVENTS\" scfile=L1405221252264C652E7F67_SC00.fits sctable=\"SC_DATA\" outfile=3C279_front_ltcube.fits dcostheta=0.025 binsz=1.0 phibins=0 tmin=0.0 tmax=0.0 file_version=\"1\" zmin=0.0 zmax=180.0 chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "Working on file L1405221252264C652E7F67_SC00.fits\n",
      ".....................!\n",
      "real 505.33\n",
      "user 502.57\n",
      "sys 0.86\n"
     ]
    }
   ],
   "source": [
    "expCube.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the counts cube\n",
    "\n",
    "**<font color='red'>Don't run these commands.</font>** (unless you want to rerun everything).\n",
    "\n",
    "The counts cube is the counts from our data file binned in space and energy.  All of the steps above use a circular ROI (or a cone, really).  Once you switch to binned analysis, you start doing things in squares.  Your counts cube can only be as big as the biggest square that can fit in the circular ROI you already selected.  \n",
    "\n",
    "![CCUBE Geometry](http://fermi.gsfc.nasa.gov/ssc/data/analysis/scitools/images/BinnedLikelihood/square_in_circle.png)\n",
    "\n",
    "This basically means that width of your square, s, should be less than $r\\times\\sqrt(2)$.  We are using an ROI with a radius, r, of 15, so we can only use a square with sides of size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.213203435596427"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "15.*np.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we're going to make a square with 100 pixels in each dimension and set the degrees/pixel to 0.2 so that we have a 20x20 degree cube.  We are also making 30 energy bins with logarithmic spacing.  You have to bin up both the front and back data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evtbin['evfile'] = '3C279_front_filtered_gti.fits'\n",
    "evtbin['outfile'] = '3C279_front_CCUBE.fits'\n",
    "evtbin['algorithm'] = 'CCUBE'\n",
    "evtbin['nxpix'] = 100\n",
    "evtbin['nypix'] = 100\n",
    "evtbin['binsz'] = 0.2\n",
    "evtbin['coordsys'] = 'CEL'\n",
    "evtbin['xref'] = 194.046527\n",
    "evtbin['yref'] =  -5.789312\n",
    "evtbin['axisrot'] = 0\n",
    "evtbin['proj'] = 'AIT'\n",
    "evtbin['ebinalg'] = 'LOG'\n",
    "evtbin['emin'] = 100\n",
    "evtbin['emax'] = 100000\n",
    "evtbin['enumbins'] = 30\n",
    "evtbin['scfile'] = 'L1405221252264C652E7F67_SC00.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtbin evfile=3C279_front_filtered_gti.fits scfile=L1405221252264C652E7F67_SC00.fits outfile=3C279_front_CCUBE.fits algorithm=\"CCUBE\" ebinalg=\"LOG\" emin=100.0 emax=100000.0 enumbins=30 ebinfile=NONE tbinalg=\"LIN\" tbinfile=NONE nxpix=100 nypix=100 binsz=0.2 coordsys=\"CEL\" xref=194.046527 yref=-5.789312 axisrot=0.0 rafield=\"RA\" decfield=\"DEC\" proj=\"AIT\" hpx_ordering_scheme=\"RING\" hpx_order=3 hpx_ebin=yes evtable=\"EVENTS\" sctable=\"SC_DATA\" efield=\"ENERGY\" tfield=\"TIME\" chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "This is gtbin version ScienceTools-v9r33p0-fssc-20140317\n",
      "real 2.01\n",
      "user 0.74\n",
      "sys 0.68\n"
     ]
    }
   ],
   "source": [
    "evtbin.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evtbin['evfile'] = '3C279_back_filtered_gti.fits'\n",
    "evtbin['outfile'] = '3C279_back_CCUBE.fits'\n",
    "evtbin['algorithm'] = 'CCUBE'\n",
    "evtbin['nxpix'] = 100\n",
    "evtbin['nypix'] = 100\n",
    "evtbin['binsz'] = 0.2\n",
    "evtbin['coordsys'] = 'CEL'\n",
    "evtbin['xref'] = 194.046527\n",
    "evtbin['yref'] =  -5.789312\n",
    "evtbin['axisrot'] = 0\n",
    "evtbin['proj'] = 'AIT'\n",
    "evtbin['ebinalg'] = 'LOG'\n",
    "evtbin['emin'] = 100\n",
    "evtbin['emax'] = 100000\n",
    "evtbin['enumbins'] = 30\n",
    "evtbin['scfile'] = 'L1405221252264C652E7F67_SC00.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtbin evfile=3C279_back_filtered_gti.fits scfile=L1405221252264C652E7F67_SC00.fits outfile=3C279_back_CCUBE.fits algorithm=\"CCUBE\" ebinalg=\"LOG\" emin=100.0 emax=100000.0 enumbins=30 ebinfile=NONE tbinalg=\"LIN\" tbinfile=NONE nxpix=100 nypix=100 binsz=0.2 coordsys=\"CEL\" xref=194.046527 yref=-5.789312 axisrot=0.0 rafield=\"RA\" decfield=\"DEC\" proj=\"AIT\" hpx_ordering_scheme=\"RING\" hpx_order=3 hpx_ebin=yes evtable=\"EVENTS\" sctable=\"SC_DATA\" efield=\"ENERGY\" tfield=\"TIME\" chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "This is gtbin version ScienceTools-v9r33p0-fssc-20140317\n",
      "real 1.87\n",
      "user 0.75\n",
      "sys 0.58\n"
     ]
    }
   ],
   "source": [
    "evtbin.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a Binned Exposure Map\n",
    "\n",
    "The binned exposure map is an exposure map binned in space and energy.  \n",
    "\n",
    "**<font color='red'>Don't run these commands.</font>** (unless you want to rerun everything).\n",
    "\n",
    "\n",
    "You first need to import the python version of 'gtexpcube2' which doesn't have a gtapp version by default.  It's easy to do (you can import any of the command line tools into python this way).  Then, you can check out the parameters with the pars function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from GtApp import GtApp\n",
    "expCube2 = GtApp('gtexpcube2','Likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' infile= cmap= outfile= irfs=\"CALDB\" nxpix=360 nypix=180 binsz=1.0 coordsys=\"GAL\" xref=0.0 yref=0.0 axisrot=0.0 proj=\"CAR\" ebinalg=\"LOG\" emin=100.0 emax=300000.0 enumbins=10 ebinfile=\"NONE\" bincalc=\"EDGE\" ignorephi=no thmax=180.0 thmin=0.0 table=\"EXPOSURE\" chatter=2 clobber=yes debug=no mode=\"ql\"'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expCube2.pars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a tricky bit here that came up when we discussed binned exposure maps.  You need to compute the exposure beyond the spatial bounds of your counts cube.  This is because in your likelihood model you need consider photons produced by a source lying outside your ROI but within range of the PSF.  There is no harm in generating a larger exposure map than you need. You could generate one for the whole sky to cover all possible regions. Since this does increase the calculation time, you might prefer something a little smaller. \n",
    "\n",
    "A good rule of thumb is to add a margin to the exposure cube spatial size that is larger than the 68% value for the PSF at the lowest energy in your analysis.  At 100 MeV the LAT has a PSF of about 10 degrees, thus, we need to add more than 10 degrees to both sides of our square, or make an exposure cube with a side length of more than 20+10+10 = 40 deg. In this case, to be safe we'll make the exposure map using 300 pixels x 300 pixels with the same pixel size (0.2 deg) that we used for the counts cube. The result is an exposure cube that is 60 deg x 60 deg and leaves plenty of margin beyond a 20 deg x 20 deg counts cube.  For the energy binning, use the same size as the counts cube.\n",
    "\n",
    "The exposure calculation requires an IRF set. For each data selection, you should use the IRF that matches the data, and so here you should specify the front or back IRFs as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expCube2['infile'] = '3C279_front_ltcube.fits'\n",
    "expCube2['cmap'] = 'none'\n",
    "expCube2['outfile'] = '3C279_front_BinnedExpMap.fits'\n",
    "expCube2['irfs'] = 'P7REP_SOURCE_V15::FRONT'\n",
    "expCube2['nxpix'] = 300\n",
    "expCube2['nypix'] = 300\n",
    "expCube2['binsz'] = 0.2\n",
    "expCube2['coordsys'] = 'CEL'\n",
    "expCube2['xref'] = 194.046527\n",
    "expCube2['yref'] = -5.789312\n",
    "expCube2['axisrot'] = 0.0\n",
    "expCube2['proj'] = 'AIT'\n",
    "expCube2['ebinalg'] = 'LOG'\n",
    "expCube2['emin'] = 100\n",
    "expCube2['emax'] = 100000\n",
    "expCube2['enumbins'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtexpcube2 infile=3C279_front_ltcube.fits cmap=none outfile=3C279_front_BinnedExpMap.fits irfs=\"P7REP_SOURCE_V15::FRONT\" nxpix=300 nypix=300 binsz=0.2 coordsys=\"CEL\" xref=194.046527 yref=-5.789312 axisrot=0.0 proj=\"AIT\" ebinalg=\"LOG\" emin=100.0 emax=100000.0 enumbins=30 ebinfile=\"NONE\" bincalc=\"EDGE\" ignorephi=no thmax=180.0 thmin=0.0 table=\"EXPOSURE\" chatter=2 clobber=yes debug=no mode=\"ql\"\n",
      "Computing binned exposure map....................!\n",
      "real 13.31\n",
      "user 12.99\n",
      "sys 0.30\n"
     ]
    }
   ],
   "source": [
    "expCube2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expCube2['infile'] = '3C279_front_ltcube.fits'\n",
    "expCube2['cmap'] = 'none'\n",
    "expCube2['outfile'] = '3C279_back_BinnedExpMap.fits'\n",
    "expCube2['irfs'] = 'P7REP_SOURCE_V15::BACK'\n",
    "expCube2['nxpix'] = 300\n",
    "expCube2['nypix'] = 300\n",
    "expCube2['binsz'] = 0.2\n",
    "expCube2['coordsys'] = 'CEL'\n",
    "expCube2['xref'] = 194.046527\n",
    "expCube2['yref'] = -5.789312\n",
    "expCube2['axisrot'] = 0.0\n",
    "expCube2['proj'] = 'AIT'\n",
    "expCube2['ebinalg'] = 'LOG'\n",
    "expCube2['emin'] = 100\n",
    "expCube2['emax'] = 100000\n",
    "expCube2['enumbins'] = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtexpcube2 infile=3C279_front_ltcube.fits cmap=none outfile=3C279_back_BinnedExpMap.fits irfs=\"P7REP_SOURCE_V15::BACK\" nxpix=300 nypix=300 binsz=0.2 coordsys=\"CEL\" xref=194.046527 yref=-5.789312 axisrot=0.0 proj=\"AIT\" ebinalg=\"LOG\" emin=100.0 emax=100000.0 enumbins=30 ebinfile=\"NONE\" bincalc=\"EDGE\" ignorephi=no thmax=180.0 thmin=0.0 table=\"EXPOSURE\" chatter=2 clobber=yes debug=no mode=\"ql\"\n",
      "Computing binned exposure map....................!\n",
      "real 12.59\n",
      "user 12.27\n",
      "sys 0.31\n"
     ]
    }
   ],
   "source": [
    "expCube2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the sourcemaps\n",
    "\n",
    "The sourcemaps step convolves the LAT response with your source model generating maps for each source in the model for use in the likelihoo calculation.\n",
    "\n",
    "**<font color='red'>Don't run these commands.</font>** (unless you want to rerun everything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srcMaps['scfile'] = 'L1405221252264C652E7F67_SC00.fits'\n",
    "srcMaps['expcube'] = '3C279_front_ltcube.fits'\n",
    "srcMaps['cmap'] = '3C279_front_CCUBE.fits'\n",
    "srcMaps['srcmdl'] = '3C279_input_model_front.xml'\n",
    "srcMaps['bexpmap'] = '3C279_front_BinnedExpMap.fits'\n",
    "srcMaps['outfile'] = '3C279_front_srcMap.fits'\n",
    "srcMaps['irfs'] = 'P7REP_SOURCE_V15::FRONT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtsrcmaps scfile=L1405221252264C652E7F67_SC00.fits sctable=\"SC_DATA\" expcube=3C279_front_ltcube.fits cmap=3C279_front_CCUBE.fits srcmdl=3C279_input_model_front.xml bexpmap=3C279_front_BinnedExpMap.fits outfile=3C279_front_srcMap.fits irfs=\"P7REP_SOURCE_V15::FRONT\" convol=yes resample=yes rfactor=2 minbinsz=0.1 ptsrc=yes psfcorr=yes emapbnds=yes copyall=no chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "Generating SourceMap for 3C 273....................!\n",
      "Generating SourceMap for 3C 279....................!\n",
      "Generating SourceMap for gll_iem_v05_rev1....................!\n",
      "Generating SourceMap for iso_source_front_v05_rev1....................!\n",
      "real 157.21\n",
      "user 156.15\n",
      "sys 0.98\n"
     ]
    }
   ],
   "source": [
    "srcMaps.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srcMaps['scfile'] = 'L1405221252264C652E7F67_SC00.fits'\n",
    "srcMaps['expcube'] = '3C279_front_ltcube.fits'\n",
    "srcMaps['cmap'] = '3C279_back_CCUBE.fits'\n",
    "srcMaps['srcmdl'] = '3C279_input_model_back.xml'\n",
    "srcMaps['bexpmap'] = '3C279_back_BinnedExpMap.fits'\n",
    "srcMaps['outfile'] = '3C279_back_srcMap.fits'\n",
    "srcMaps['irfs'] = 'P7REP_SOURCE_V15::BACK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time -p /home/fermi2014/AstroSoft/ScienceTools/x86_64-unknown-linux-gnu-libc2.12/bin/gtsrcmaps scfile=L1405221252264C652E7F67_SC00.fits sctable=\"SC_DATA\" expcube=3C279_front_ltcube.fits cmap=3C279_back_CCUBE.fits srcmdl=3C279_input_model_back.xml bexpmap=3C279_back_BinnedExpMap.fits outfile=3C279_back_srcMap.fits irfs=\"P7REP_SOURCE_V15::BACK\" convol=yes resample=yes rfactor=2 minbinsz=0.1 ptsrc=yes psfcorr=yes emapbnds=yes copyall=no chatter=2 clobber=yes debug=no gui=no mode=\"ql\"\n",
      "Generating SourceMap for 3C 273....................!\n",
      "Generating SourceMap for 3C 279....................!\n",
      "Generating SourceMap for gll_iem_v05_rev1....................!\n",
      "Generating SourceMap for iso_source_back_v05_rev1....................!\n",
      "real 141.03\n",
      "user 139.98\n",
      "sys 0.96\n"
     ]
    }
   ],
   "source": [
    "srcMaps.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, Perform the Likelihood Analysis\n",
    "\n",
    "**<font color='red'>Start running commands now if you want.</font>**\n",
    "\n",
    "First, import the BinnedAnalysis and SummedAnalysis libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from BinnedAnalysis import *\n",
    "from SummedLikelihood import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a likelihood object for both the front and back data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "like_f = binnedAnalysis(irfs='P7REP_SOURCE_V15::FRONT', \n",
    "                        expcube='3C279_front_ltcube.fits', \n",
    "                        srcmdl='3C279_input_model_front.xml',\n",
    "                        optimizer='NEWMINUIT',\n",
    "                        cmap='3C279_front_srcMap.fits',\n",
    "                        bexpmap='3C279_front_BinnedExpMap.fits')\n",
    "\n",
    "like_b = binnedAnalysis(irfs='P7REP_SOURCE_V15::BACK', \n",
    "                        expcube='3C279_front_ltcube.fits', \n",
    "                        srcmdl='3C279_input_model_back.xml',\n",
    "                        optimizer='NEWMINUIT',\n",
    "                        cmap='3C279_back_srcMap.fits',\n",
    "                        bexpmap='3C279_back_BinnedExpMap.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create the summed likelihood object and add the two likelihood objects, one for the front selection and the second for the back selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summed_like = SummedLikelihood()\n",
    "summed_like.addComponent(like_f)\n",
    "summed_like.addComponent(like_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the fit and print out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83296.65845449014"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_like.fit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3C 273\n",
       "   Spectrum: PowerLaw\n",
       "0      Prefactor:  1.128e+01  4.666e-01  1.000e-03  1.000e+03 ( 1.000e-09)\n",
       "1          Index: -2.591e+00  2.913e-02 -5.000e+00 -1.000e+00 ( 1.000e+00)\n",
       "2          Scale:  1.000e+02  0.000e+00  3.000e+01  2.000e+03 ( 1.000e+00) fixed\n",
       "\n",
       "3C 279\n",
       "   Spectrum: PowerLaw\n",
       "3      Prefactor:  4.313e+00  2.889e-01  1.000e-03  1.000e+03 ( 1.000e-09)\n",
       "4          Index: -2.282e+00  3.555e-02 -5.000e+00  0.000e+00 ( 1.000e+00)\n",
       "5          Scale:  1.000e+02  0.000e+00  3.000e+01  2.000e+03 ( 1.000e+00) fixed\n",
       "\n",
       "gll_iem_v05_rev1\n",
       "   Spectrum: ConstantValue\n",
       "6          Value:  1.422e+00  3.644e-02  0.000e+00  1.000e+01 ( 1.000e+00)\n",
       "\n",
       "iso_source_front_v05_rev1\n",
       "   Spectrum: FileFunction\n",
       "7     Normalization:  1.217e+00  4.046e-02  1.000e-05  1.000e+03 ( 1.000e+00)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summed_like.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have maximized the likelihood for our model simultaneously for two data sets with distinct IRFs, the front and back event type selections. Let's compare with the standard analysis that uses only one data set containing both Front and Back event types that are represented by a single, combined IRF set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
